<!DOCTYPE html>
<html lang="ja">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>ç‰¹å¾´é‡ãƒãƒƒãƒãƒ³ã‚°</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three@0.128/examples/js/loaders/GLTFLoader.js"></script>
    <style>
      body {
        margin: 0;
        overflow: hidden;
      }
      video {
        position: absolute;
        top: 0;
        left: 0;
        width: 100vw;
        height: 100vh;
        object-fit: cover;
        z-index: -1;
      }
    </style>
  </head>
  <body>
    <!-- <div style="display: flex; gap: 50px"> -->
    <video id="video" autoplay></video>
    <canvas
      id="canvas"
      width="640"
      height="480"
      style="position: absolute; top: 0; left: 0; display: none"
    >
    </canvas>
    <div
      style="
        position: absolute;
        top: 50px;
        left: 200px;
        width: 200px;
        height: 360px;
        border: 1px solid red;
        display: none;
      "
    >
      <p id="status">Loading OpenCV...</p>
      <p id="width">Loading OpenCV...</p>
      <p id="height">Loading OpenCV...</p>
    </div>

    <script>
      let video = document.getElementById("video");
      let canvas = document.getElementById("canvas");
      let ctx = canvas.getContext("2d");
      let statusText = document.getElementById("status");
      let widthText = document.getElementById("width");
      let heightText = document.getElementById("height");
      let interval;

      function loadOpenCv() {
        console.log("Loading OpenCV.js...");
        let script = document.createElement("script");
        console.log("script");
        script.src = "https://docs.opencv.org/4.10.0/opencv.js";
        console.log("script.src");
        script.onload = onOpenCvReady;
        console.log("script.onload");
        script.onerror = onOpenCvError;
        console.log("script.onerror");
        document.body.appendChild(script);
        console.log("document.body.appendChild(script)");
      }

      function onOpenCvReady() {
        console.log("OpenCV.js script loaded.");
        statusText.textContent = "OpenCV.js script loaded, initializing...";
        checkOpenCvReady();
      }

      function onOpenCvError() {
        console.error("Failed to load OpenCV.js!");
        statusText.textContent = "Failed to load OpenCV.js!";
      }

      function checkOpenCvReady() {
        if (typeof cv !== "undefined" && cv.getBuildInformation) {
          console.log("OpenCV.js is ready.");
          statusText.textContent = "OpenCV.js is ready.";
          startProcessing();
        } else {
          console.log("OpenCV.js is not ready.");
          setTimeout(checkOpenCvReady, 100);
        }
      }

      function startProcessing() {
        navigator.mediaDevices.getUserMedia({ video: true }).then((stream) => {
          video.srcObject = stream;
        });

        interval = setInterval(processImage, 1000);
      }

      function processImage() {
        if (typeof cv === "undefined" || !cv.imread) {
          console.log("OpenCV is not fully initialized yet.");
          return;
        }

        let statusText = document.getElementById("status");

        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
        let src = cv.imread(canvas);

        // ç”»åƒã®ã‚µã‚¤ã‚ºå–å¾—
        let width = src.cols;
        let height = src.rows;
        widthText.textContent = "width: " + width;
        heightText.textContent = "height: " + height;

        // æ¨ªã®å¹…ã‚’é«˜ã•ã® 1/2 ã«ã™ã‚‹
        let cropWidth = Math.floor(height * 0.4);
        let cropHeight = height * 0.8; // ç¸¦ã¯ãƒ•ãƒ«ã‚µã‚¤ã‚º

        // ä¸­å¤®ä½ç½®ã‚’è¨ˆç®—
        let centerX = Math.floor(width / 2);

        // åˆ‡ã‚Šå–ã‚Šç¯„å›²ã®æŒ‡å®š
        let rect = new cv.Rect(
          centerX - Math.floor(cropWidth / 2), // Xåº§æ¨™ (æ¨ªä¸­å¤®)
          0, // Yåº§æ¨™ (ä¸Šç«¯ã‹ã‚‰ã‚¹ã‚¿ãƒ¼ãƒˆ)
          cropWidth, // åˆ‡ã‚Šå–ã‚‹å¹…
          cropHeight // åˆ‡ã‚Šå–ã‚‹é«˜ã•
        );

        let cropped = src.roi(rect); // æŒ‡å®šç¯„å›²ã‚’åˆ‡ã‚Šå–ã‚‹

        // å‰å‡¦ç†ï¼ˆã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ« & ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·èª¿ï¼‰
        cv.cvtColor(cropped, cropped, cv.COLOR_RGBA2GRAY, 0);
        cv.GaussianBlur(cropped, cropped, new cv.Size(3, 3), 0);
        cv.equalizeHist(cropped, cropped);

        let orb = new cv.ORB();
        let keypoints = new cv.KeyPointVector();
        let descriptors = new cv.Mat();
        orb.detectAndCompute(cropped, new cv.Mat(), keypoints, descriptors);

        fetch("features.json")
          .then((response) => response.json())
          .then((savedFeatures) => {
            let savedDescriptors = new cv.Mat();
            let descriptorArray = savedFeatures.descriptors.flat();

            if (descriptorArray.length % 32 !== 0) {
              console.error("ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãŒä¸æ­£ã§ã™: ", descriptorArray.length);
              return;
            }

            let descriptorUint8Array = new Uint8Array(descriptorArray);
            savedDescriptors.create(descriptorArray.length / 32, 32, cv.CV_8U);
            savedDescriptors.data.set(descriptorUint8Array);

            if (descriptors.empty()) {
              console.log("No descriptors found.");
              statusText.textContent = "è‰¯ã„ãƒãƒƒãƒæ•°: 0";
              return;
            }

            let bf = new cv.BFMatcher(cv.NORM_HAMMING, false);
            let matches = new cv.DMatchVectorVector();
            bf.knnMatch(descriptors, savedDescriptors, matches, 2);

            let goodMatches = 0;
            for (let i = 0; i < matches.size(); i++) {
              let m = matches.get(i).get(0);
              let n = matches.get(i).get(1);
              if (m.distance < 0.8 * n.distance) {
                goodMatches++;
              }
            }

            console.log("è‰¯ã„ãƒãƒƒãƒæ•°:", goodMatches);
            statusText.textContent = "è‰¯ã„ãƒãƒƒãƒæ•°: " + goodMatches;

            // ãƒšãƒ¼ã‚¸é·ç§»ã‚’ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
            if (goodMatches > 11) {
              model.visible = true;
              //  setInterval(processImage, 1000)ã‚’æ­¢ã‚ã‚‹ã€‚
              clearInterval(interval);
            }

            src.delete();
            cropped.delete();
            descriptors.delete();
            keypoints.delete();
            matches.delete();
            savedDescriptors.delete();
          });
      }

      async function startCamera() {
        let constraints = {
          video: {
            facingMode: "environment", // å¤–ã‚«ãƒ¡ãƒ©ã‚’å„ªå…ˆ
            width: { ideal: 1280 }, // è§£åƒåº¦ã‚’èª¿æ•´ï¼ˆ1280x720 ä»¥ä¸Šã‚’æ¨å¥¨ï¼‰
            height: { ideal: 720 },
          },
        };

        try {
          let stream = await navigator.mediaDevices.getUserMedia(constraints);
          video.srcObject = stream;
        } catch (error) {
          console.error("ã‚«ãƒ¡ãƒ©ã®èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸ:", error);
          selectCameraManually(); // æ‰‹å‹•ã§ã‚«ãƒ¡ãƒ©ã‚’é¸æŠ
        }
      }

      // ã‚«ãƒ¡ãƒ©ä¸€è¦§ã‚’å–å¾—ã—ã€å¤–ã‚«ãƒ¡ãƒ©ã‚’æ¢ã™
      async function selectCameraManually() {
        let devices = await navigator.mediaDevices.enumerateDevices();
        let videoDevices = devices.filter(
          (device) => device.kind === "videoinput"
        );

        if (videoDevices.length === 0) {
          console.error("ã‚«ãƒ¡ãƒ©ãƒ‡ãƒã‚¤ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“");
          return;
        }

        let backCamera = videoDevices.find((device) =>
          device.label.toLowerCase().includes("back")
        );

        let constraints = {
          video: {
            deviceId: backCamera
              ? { exact: backCamera.deviceId }
              : { exact: videoDevices[0].deviceId },
          },
        };

        try {
          let stream = await navigator.mediaDevices.getUserMedia(constraints);
          video.srcObject = stream;
        } catch (error) {
          console.error("ã‚«ãƒ¡ãƒ©ã®æ‰‹å‹•é¸æŠã«å¤±æ•—ã—ã¾ã—ãŸ:", error);
        }
      }

      // ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿æ™‚ã«å¤–ã‚«ãƒ¡ãƒ©ã‚’èµ·å‹•
      window.onload = startCamera;

      // ğŸ“Œ ã‚«ãƒ¡ãƒ©æ˜ åƒã®å–å¾—
      navigator.mediaDevices
        .getUserMedia({ video: { facingMode: "environment" } })
        .then((stream) => {
          video.srcObject = stream;
        })
        .catch((err) => {
          console.error("ã‚«ãƒ¡ãƒ©ã®ã‚¢ã‚¯ã‚»ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸ:", err);
        });

      // ğŸ“Œ Three.js ã®ã‚·ãƒ¼ãƒ³ã‚’ä½œæˆ
      const scene = new THREE.Scene();

      // ğŸ“Œ ã‚«ãƒ¡ãƒ©è¨­å®š
      const camera = new THREE.PerspectiveCamera(
        75,
        window.innerWidth / window.innerHeight,
        0.1,
        1000
      );
      camera.position.set(0, 0, 2); // 3Dã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¡¨ç¤ºã™ã‚‹ä½ç½®

      // ğŸ“Œ ãƒ¬ãƒ³ãƒ€ãƒ©ãƒ¼è¨­å®šï¼ˆèƒŒæ™¯é€æ˜ï¼‰
      const renderer = new THREE.WebGLRenderer({ alpha: true });
      renderer.setSize(window.innerWidth, window.innerHeight);
      document.body.appendChild(renderer.domElement);

      // ğŸ“Œ ãƒ©ã‚¤ãƒˆè¨­å®š
      const ambientLight = new THREE.AmbientLight(0xffffff, 1.2); // ç’°å¢ƒå…‰
      scene.add(ambientLight);

      const directionalLight = new THREE.DirectionalLight(0xffffff, 2);
      directionalLight.position.set(10, 10, 10); // ãƒ©ã‚¤ãƒˆã®æ–¹å‘
      scene.add(directionalLight);

      const pointLight = new THREE.PointLight(0xffffff, 2, 100);
      pointLight.position.set(0, 5, 5);
      scene.add(pointLight);

      // ğŸ¯ ãƒ¢ãƒ‡ãƒ«ã‚’ç›´æ¥ç…§ã‚‰ã™ SpotLightï¼ˆé»„è‰²ã®å¼·ã‚ã®ãƒ©ã‚¤ãƒˆï¼‰
      const spotLight = new THREE.SpotLight(0xffffff, 3, 300, Math.PI / 6, 0.5);
      spotLight.position.set(0, 10, 10);
      scene.add(spotLight);

      // ğŸ“Œ 3Dãƒ¢ãƒ‡ãƒ«ï¼ˆPikachu.glbï¼‰ã‚’ãƒ­ãƒ¼ãƒ‰
      let model;
      const loader = new THREE.GLTFLoader();
      loader.load("pikachu.glb", function (gltf) {
        model = gltf.scene;
        model.scale.set(0.04, 0.04, 0.04); // ã‚µã‚¤ã‚ºèª¿æ•´
        model.position.set(0, -1, 0); // ä½ç½®èª¿æ•´
        model.visible = false;
        scene.add(model);
      });

      // ğŸ“Œ ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ«ãƒ¼ãƒ—
      function animate() {
        requestAnimationFrame(animate);
        if (model) {
          model.rotation.y += 0.01; // ãƒ¢ãƒ‡ãƒ«ã‚’å›è»¢
        }
        renderer.render(scene, camera);
      }
      animate();

      // ğŸ“Œ ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ãƒªã‚µã‚¤ã‚ºå¯¾å¿œ
      window.addEventListener("resize", () => {
        renderer.setSize(window.innerWidth, window.innerHeight);
        camera.aspect = window.innerWidth / window.innerHeight;
        camera.updateProjectionMatrix();
      });

      window.onload = loadOpenCv; // OpenCV.js ã‚’å‹•çš„ã«ãƒ­ãƒ¼ãƒ‰
    </script>
  </body>
</html>
